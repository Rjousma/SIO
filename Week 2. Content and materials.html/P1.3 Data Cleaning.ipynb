{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Loading the Case Study Data in a Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with Jupyter notebooks\n",
    "\n",
    "There are two kinds of cells: markdown and 'code' cells. This one is marked as markdown. The next one is a `markdown` cell, followed by a 'code' cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Business context of the data\n",
    "\n",
    "Our consultancy firm is contracted by a credit card client. The client have offered us a data set with data from account holders. Each row corresponds to one customer's account data. The data contains monthly records, over a period of 6 months. Data from 30,000 acount holders are provided. The data are classified according to whether an account owner has defaulted, after a six month period. In practice this means that the account holder did not make the minimum required payment. \n",
    "\n",
    "# The goal for data analytics\n",
    "\n",
    "The client wants us to develop a model to predic whether in the month after the six-month period of the historical data, e account holder will default or not. \n",
    "\n",
    "\n",
    "# The data set\n",
    "\n",
    "The data set is a modified version of the following: \n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients. \n",
    "\n",
    "This is taken from the UCI Machine Learning Repository, a public repository of bencmarking datasets. .\n",
    "Have a look at that web page to find out more abot the data characteristics. Can you summarise the key characteristics?\n",
    "\n",
    "Next, let's turn our attention to the code needed to load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the first command we imported the pandas data management library. \n",
    "\n",
    "Next we will use it to load our first data set. \n",
    "\n",
    "Data loading is done in the next code cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:\\Python\\Code\\SIO\\Practicals\\Practicals 1\\Data'\n",
    "#you may set your own path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel(\"default_of_credit_card_clients.xls\") \n",
    "#df = pd.read_csv('default_of_credit_card_clients.csv',index_col='ID')\n",
    "df = pd.read_csv('default_of_credit_card_clients.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a separate directory Data, then we need to set the path. Otherwise we just read the file from the current directory. The file is available on Brightspace. Here we read the 'ID' as attribute, so we can manipulate it. If we wanted to register the 'ID' values as the actual ID, we would have useed the index_col='ID' option above. \n",
    "We start our exploratory analysis by inspecting the size of the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this file has 30000 records. We have 26 attributes but we have loaded also the ID as attribute so as to be able to include the ID in the data manipulates. \n",
    "\n",
    "We can also execute direct value assignment commands and view their outcomes, as below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Check Data Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains monthly credit card account data, for a period of six months. Let's perform a quality check to ensure we have the data for the accounts as expected. The account ID distinguishes one account from the other. We can check unique IDs with Pandas with the function `.nunique()`. But first let's check our data structure. To do so we first build an Index of he different columns in the table. We will use the .columns method of the pandas DataFrame to see the column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE',\n",
       "       'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1',\n",
       "       'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
       "       'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'default payment next month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then check the column headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>798fc410-45c1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8a8c8f3b-8eb4</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>85698822-43f5</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0737c11b-be42</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3b7f77cc-dbc0</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE PAY_1  \\\n",
       "0           0  798fc410-45c1      20000    2          2         1   24     2   \n",
       "1           1  8a8c8f3b-8eb4     120000    2          2         2   26    -1   \n",
       "2           2  85698822-43f5      90000    2          2         2   34     0   \n",
       "3           3  0737c11b-be42      50000    2          2         1   37     0   \n",
       "4           4  3b7f77cc-dbc0      50000    1          2         1   57    -1   \n",
       "\n",
       "   PAY_2  PAY_3  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0      2     -1  ...          0          0          0         0       689   \n",
       "1      2      0  ...       3272       3455       3261         0      1000   \n",
       "2      0      0  ...      14331      14948      15549      1518      1500   \n",
       "3      0      0  ...      28314      28959      29547      2000      2019   \n",
       "4      0     -1  ...      20940      19146      19131      2000     36681   \n",
       "\n",
       "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0         0                           1  \n",
       "1      1000      1000         0      2000                           1  \n",
       "2      1000      1000      1000      5000                           0  \n",
       "3      1200      1100      1069      1000                           0  \n",
       "4     10000      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we check the unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29687"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting! We have fewer unique IDs than rows, so we clearly have duplicates! We can check the number of occurences of each ID by counting them, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ad23fe5c-7b09    2\n",
       "1fb3e3e6-a68d    2\n",
       "89f8f447-fca8    2\n",
       "7c9b7473-cc2f    2\n",
       "90330d02-82d9    2\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_counts = df['ID'].value_counts()\n",
    "id_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    29374\n",
       "2      313\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_counts.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know that we have 29374 IDs which appear only once but we also hae 313 which appear twice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous, most comments have now been taken out for compactness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the data\n",
    "\n",
    "Before we progress with data manipulation, let's focus on how we can filter the data using a range of 'masks' - these are Boolean operations on the data. we will first use synthetic data to illustrate this. We will import the main numerical processing packge, namely NumPy. This has among other capabilities for generating random numbers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define 'seed' numbers for the random data generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = default_rng(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will define the range values of the data. Note that the upper value is never reached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_integers = rg.integers(low=1,high=5,size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_integers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are interested in identifing the locations of all random integers equal to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_equal_to_3 = random_integers == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just focus on the first rows again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_equal_to_3[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how many rows have a random number with value that equals to 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(is_equal_to_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can verify this below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_integers[is_equal_to_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have familiarised with using bolean masks for filtering data, let's continue with our data integrity check. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Continue with Data Integrity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now examine in more detail the duplicate IDs. To do so, let's create a Boolean mask to locate the duplicate IDs. We name this 'mask dupe_mask'. Let's display the first five elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_mask = id_counts == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ad23fe5c-7b09    True\n",
       "1fb3e3e6-a68d    True\n",
       "89f8f447-fca8    True\n",
       "7c9b7473-cc2f    True\n",
       "90330d02-82d9    True\n",
       "Name: ID, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_mask[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the '5' in the command above with another number and observe a different number of records. Let's keep it '5'now and inspect the duplicate ID records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ad23fe5c-7b09', '1fb3e3e6-a68d', '89f8f447-fca8', '7c9b7473-cc2f',\n",
       "       '90330d02-82d9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_counts.index[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to access and inspect these records, let's store their ID numbers in a variable named 'dupe_ids' and inspect the first 10 such records:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_ids = id_counts.index[dupe_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ad23fe5c-7b09', '1fb3e3e6-a68d', '89f8f447-fca8', '7c9b7473-cc2f',\n",
       "       '90330d02-82d9', '2a793ecf-05c6', '75938fec-e5ec', '7be61027-a493',\n",
       "       'a3a5c0fc-fdd6', 'b44b81b2-7789'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check the cardinality of the dupe_ids variable (i.e. how many records it contains). We use 'len' for this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_ids = list(dupe_ids)\n",
    "len(dupe_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right - as expected. So we focus again on the first 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ad23fe5c-7b09',\n",
       " '1fb3e3e6-a68d',\n",
       " '89f8f447-fca8',\n",
       " '7c9b7473-cc2f',\n",
       " '90330d02-82d9']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupe_ids[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected the records with the duplicate IDs, we wish to inspect their data in more detail. Is there anything different in the values of these records which have identical IDs? Our approach to do so is this: we first focus on the data records with the first 3 duplicate IDs, as a sample. First we focus on finding the rows which contain these 3 IDs. The first three IDs are dupe_ids[0:3]. \n",
    "\n",
    "We will use the '.isin' method to create another logical mask. We will pass the earlier selected list of IDs through this mask and apply this on the larger dataframe to display the rows that have this ID. We use the .loc method for locating these IDs. The '.isin' method is NESTED within the .loc statement: this indexes the datafame to select the location of all rows containing a True value in the logical mask. The : in the second argument of the loc implies that all columns will be seleted. So in this way we filter the Dataframe so as to view all the columns for the first three duplicate IDs. This is not very comlex filtering but still it is a sign of the compactness of the Python language that a single command with this nested structure produces this outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>5033</td>\n",
       "      <td>89f8f447-fca8</td>\n",
       "      <td>320000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>169371</td>\n",
       "      <td>172868</td>\n",
       "      <td>150827</td>\n",
       "      <td>8000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5500</td>\n",
       "      <td>6100</td>\n",
       "      <td>6000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5133</th>\n",
       "      <td>5133</td>\n",
       "      <td>89f8f447-fca8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16727</th>\n",
       "      <td>16727</td>\n",
       "      <td>1fb3e3e6-a68d</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27394</td>\n",
       "      <td>29922</td>\n",
       "      <td>31879</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>3000</td>\n",
       "      <td>2600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16827</th>\n",
       "      <td>16827</td>\n",
       "      <td>1fb3e3e6-a68d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29685</th>\n",
       "      <td>29685</td>\n",
       "      <td>ad23fe5c-7b09</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12882</td>\n",
       "      <td>8131</td>\n",
       "      <td>3983</td>\n",
       "      <td>3000</td>\n",
       "      <td>2871</td>\n",
       "      <td>1000</td>\n",
       "      <td>163</td>\n",
       "      <td>3983</td>\n",
       "      <td>3771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29785</th>\n",
       "      <td>29785</td>\n",
       "      <td>ad23fe5c-7b09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  \\\n",
       "5033         5033  89f8f447-fca8     320000    2          2         1   32   \n",
       "5133         5133  89f8f447-fca8          0    0          0         0    0   \n",
       "16727       16727  1fb3e3e6-a68d      80000    1          2         2   33   \n",
       "16827       16827  1fb3e3e6-a68d          0    0          0         0    0   \n",
       "29685       29685  ad23fe5c-7b09      50000    1          3         1   32   \n",
       "29785       29785  ad23fe5c-7b09          0    0          0         0    0   \n",
       "\n",
       "      PAY_1  PAY_2  PAY_3  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  \\\n",
       "5033      0      0      0  ...     169371     172868     150827      8000   \n",
       "5133      0      0      0  ...          0          0          0         0   \n",
       "16727     2      2      0  ...      27394      29922      31879         0   \n",
       "16827     0      0      0  ...          0          0          0         0   \n",
       "29685     0      0      0  ...      12882       8131       3983      3000   \n",
       "29785     0      0      0  ...          0          0          0         0   \n",
       "\n",
       "       PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "5033       8000      5500      6100      6000      5000   \n",
       "5133          0         0         0         0         0   \n",
       "16727      2000      2000      3000      2600         0   \n",
       "16827         0         0         0         0         0   \n",
       "29685      2871      1000       163      3983      3771   \n",
       "29785         0         0         0         0         0   \n",
       "\n",
       "       default payment next month  \n",
       "5033                            0  \n",
       "5133                            0  \n",
       "16727                           1  \n",
       "16827                           0  \n",
       "29685                           1  \n",
       "29785                           0  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['ID'].isin(dupe_ids[0:3]),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets interesting. For each pair of rows with duplicate IDs, one row contains potentially valid data, but the other one only contains 0s! It is most likley that a data clearning process would be expected to delete all such eroneous data. You can't for example have an age of 0 or a credit limit of 0 and stil be part of the data processing! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to delete all rows with data values of zero (excluding the ID attribute). First we inspect the unique values in the data to see if there are any other problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get the attribute names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'default payment next month']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we count the unique values for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                    30000\n",
      "ID                            29687\n",
      "LIMIT_BAL                        82\n",
      "SEX                               3\n",
      "EDUCATION                         7\n",
      "MARRIAGE                          4\n",
      "AGE                              57\n",
      "PAY_1                            12\n",
      "PAY_2                            11\n",
      "PAY_3                            11\n",
      "PAY_4                            11\n",
      "PAY_5                            10\n",
      "PAY_6                            10\n",
      "BILL_AMT1                     22510\n",
      "BILL_AMT2                     22146\n",
      "BILL_AMT3                     21822\n",
      "BILL_AMT4                     21350\n",
      "BILL_AMT5                     20831\n",
      "BILL_AMT6                     20417\n",
      "PAY_AMT1                       7890\n",
      "PAY_AMT2                       7847\n",
      "PAY_AMT3                       7463\n",
      "PAY_AMT4                       6901\n",
      "PAY_AMT5                       6857\n",
      "PAY_AMT6                       6895\n",
      "default payment next month        2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_of_unique_values = df.nunique()\n",
    "print(count_of_unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we inspect the unique values for each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 29997 29998 29999]\n",
      "['798fc410-45c1' '8a8c8f3b-8eb4' '85698822-43f5' ... '95cdd3e7-4f24'\n",
      " '00d03f02-04cd' '15d69f9f-5ad3']\n",
      "[  20000  120000   90000   50000  500000  100000  140000  200000  260000\n",
      "  630000   70000  250000  320000  360000  180000  130000  450000   60000\n",
      "  230000  160000  280000   10000   40000  210000  150000  380000  310000\n",
      "  400000   80000  290000  340000  300000   30000  240000  470000  480000\n",
      "  350000  330000  110000  420000  170000  370000  270000  220000  190000\n",
      "       0  510000  460000  440000  410000  490000  390000  580000  600000\n",
      "  620000  610000  700000  670000  680000  430000  550000  540000 1000000\n",
      "  530000  710000  560000  520000  750000  640000   16000  570000  590000\n",
      "  660000  720000  327680  740000  800000  760000  690000  650000  780000\n",
      "  730000]\n",
      "[2 1 0]\n",
      "[2 1 3 5 0 4 6]\n",
      "[1 2 3 0]\n",
      "[24 26 34 37 57 29 23 28 35 51 41 30 49 39 40 27 47 33 32 54 58 22 25 31\n",
      " 46 42 43 45 56 44 53 38 63 36 52 48 55 60 50  0 75 61 73 59 21 67 66 62\n",
      " 70 72 64 65 71 69 68 79 74]\n",
      "['2' '-1' '0' '-2' '1' 'Not available' '3' '4' '8' '7' '5' '6']\n",
      "[ 2  0 -1 -2  3  5  7  4  1  6  8]\n",
      "[-1  0  2 -2  3  4  6  7  1  5  8]\n",
      "[-1  0 -2  2  3  4  5  7  6  1  8]\n",
      "[-2  0 -1  2  3  5  4  7  8  6]\n",
      "[-2  2  0 -1  3  6  4  7  8  5]\n",
      "[ 3913  2682 29239 ...  1683 -1645 47929]\n",
      "[ 3102  1725 14027 ...  3356 78379 48905]\n",
      "[  689  2682 13559 ...  2758 76304 49764]\n",
      "[    0  3272 14331 ... 20878 52774 36535]\n",
      "[    0  3455 14948 ... 31237  5190 32428]\n",
      "[    0  3261 15549 ... 19357 48944 15313]\n",
      "[    0  1518  2000 ... 10029  9054 85900]\n",
      "[   689   1000   1500 ...   2977 111784   3526]\n",
      "[     0   1000   1200 ... 349395   8907  25128]\n",
      "[    0  1000  1100 ...  2556 10115  8049]\n",
      "[    0  1000  1069 ...  8040  3319 52964]\n",
      "[     0   2000   5000 ...  70052 220076  16080]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "for index in column_names :\n",
    "    uniquenamesincolumn = df[index].unique() \n",
    "    print(uniquenamesincolumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Attribute 'PAY_1' appears to have a 'Not available' value in at least one of the records. We will delete these records next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.PAY_1 != 'Not available']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will examine our data records again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                    26979\n",
      "ID                            26704\n",
      "LIMIT_BAL                        81\n",
      "SEX                               3\n",
      "EDUCATION                         7\n",
      "MARRIAGE                          4\n",
      "AGE                              57\n",
      "PAY_1                            11\n",
      "PAY_2                            11\n",
      "PAY_3                            11\n",
      "PAY_4                            11\n",
      "PAY_5                            10\n",
      "PAY_6                            10\n",
      "BILL_AMT1                     20519\n",
      "BILL_AMT2                     20165\n",
      "BILL_AMT3                     19852\n",
      "BILL_AMT4                     19472\n",
      "BILL_AMT5                     19002\n",
      "BILL_AMT6                     18642\n",
      "PAY_AMT1                       7425\n",
      "PAY_AMT2                       7361\n",
      "PAY_AMT3                       7025\n",
      "PAY_AMT4                       6463\n",
      "PAY_AMT5                       6447\n",
      "PAY_AMT6                       6471\n",
      "default payment next month        2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_of_unique_values = df.nunique()\n",
    "print(count_of_unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have confirmed that there is one unique value less in PAY_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 29997 29998 29999]\n",
      "['798fc410-45c1' '8a8c8f3b-8eb4' '85698822-43f5' ... '95cdd3e7-4f24'\n",
      " '00d03f02-04cd' '15d69f9f-5ad3']\n",
      "[ 20000 120000  90000  50000 500000 100000 140000 200000 260000 630000\n",
      "  70000 250000 360000 180000 130000 450000  60000 230000 160000 280000\n",
      "  10000  40000 210000 150000 380000 310000 400000  80000 290000 340000\n",
      " 300000  30000 240000 470000 480000 350000 330000 110000 420000 170000\n",
      " 370000 270000 220000 320000 190000      0 510000 460000 440000 410000\n",
      " 490000 390000 580000 600000 620000 610000 700000 670000 680000 430000\n",
      " 550000 540000 530000 710000 520000 750000 640000 570000 590000 660000\n",
      " 560000 720000 327680 740000 800000 760000 690000 650000 780000 730000\n",
      "  16000]\n",
      "[2 1 0]\n",
      "[2 1 3 5 0 4 6]\n",
      "[1 2 3 0]\n",
      "[24 26 34 37 57 29 23 28 35 51 41 30 49 39 40 27 33 32 54 58 22 25 31 46\n",
      " 42 43 45 56 44 53 38 63 36 52 47 48 55 60 50  0 75 61 73 59 21 67 66 62\n",
      " 70 72 64 65 71 68 69 79 74]\n",
      "['2' '-1' '0' '-2' '1' '3' '4' '8' '7' '5' '6']\n",
      "[ 2  0 -1 -2  3  5  7  4  1  6  8]\n",
      "[-1  0  2 -2  3  4  6  7  1  5  8]\n",
      "[-1  0 -2  2  3  4  5  7  6  1  8]\n",
      "[-2  0 -1  2  3  5  4  7  8  6]\n",
      "[-2  2  0 -1  3  6  4  7  8  5]\n",
      "[ 3913  2682 29239 ...  1683 -1645 47929]\n",
      "[ 3102  1725 14027 ...  3356 78379 48905]\n",
      "[  689  2682 13559 ...  2758 76304 49764]\n",
      "[    0  3272 14331 ... 20878 52774 36535]\n",
      "[    0  3455 14948 ... 31237  5190 32428]\n",
      "[    0  3261 15549 ... 19357 48944 15313]\n",
      "[    0  1518  2000 ... 10029  9054 85900]\n",
      "[   689   1000   1500 ...   2720 111784   3526]\n",
      "[     0   1000   1200 ... 349395   8907  25128]\n",
      "[    0  1000  1100 ...  2556 10115  8049]\n",
      "[    0  1000  1069 ...  3520  8040 52964]\n",
      "[     0   2000   5000 ...  70052 220076  16080]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "for index in column_names :\n",
    "    uniquenamesincolumn = df[index].unique() \n",
    "    print(uniquenamesincolumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we don't see the 'Not available' value any more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the fact that we had this issue, impacted on the type of variable that PAY_1 was. We inspect the data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     int64\n",
       "ID                            object\n",
       "LIMIT_BAL                      int64\n",
       "SEX                            int64\n",
       "EDUCATION                      int64\n",
       "MARRIAGE                       int64\n",
       "AGE                            int64\n",
       "PAY_1                         object\n",
       "PAY_2                          int64\n",
       "PAY_3                          int64\n",
       "PAY_4                          int64\n",
       "PAY_5                          int64\n",
       "PAY_6                          int64\n",
       "BILL_AMT1                      int64\n",
       "BILL_AMT2                      int64\n",
       "BILL_AMT3                      int64\n",
       "BILL_AMT4                      int64\n",
       "BILL_AMT5                      int64\n",
       "BILL_AMT6                      int64\n",
       "PAY_AMT1                       int64\n",
       "PAY_AMT2                       int64\n",
       "PAY_AMT3                       int64\n",
       "PAY_AMT4                       int64\n",
       "PAY_AMT5                       int64\n",
       "PAY_AMT6                       int64\n",
       "default payment next month     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAY_1 is the only attribute which does not appear to be of Integer type. We will convert it first to Integer type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'PAY_1':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     int64\n",
       "ID                            object\n",
       "LIMIT_BAL                      int64\n",
       "SEX                            int64\n",
       "EDUCATION                      int64\n",
       "MARRIAGE                       int64\n",
       "AGE                            int64\n",
       "PAY_1                          int32\n",
       "PAY_2                          int64\n",
       "PAY_3                          int64\n",
       "PAY_4                          int64\n",
       "PAY_5                          int64\n",
       "PAY_6                          int64\n",
       "BILL_AMT1                      int64\n",
       "BILL_AMT2                      int64\n",
       "BILL_AMT3                      int64\n",
       "BILL_AMT4                      int64\n",
       "BILL_AMT5                      int64\n",
       "BILL_AMT6                      int64\n",
       "PAY_AMT1                       int64\n",
       "PAY_AMT2                       int64\n",
       "PAY_AMT3                       int64\n",
       "PAY_AMT4                       int64\n",
       "PAY_AMT5                       int64\n",
       "PAY_AMT6                       int64\n",
       "default payment next month     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all attributed apart from ID are of Integer type. However, they are of unecessary high presicion (int64). It does not really matter for the present example, but it is possible to convert them all to the same type of integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({col: 'int32' for col in df.select_dtypes('int64').columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     int32\n",
       "ID                            object\n",
       "LIMIT_BAL                      int32\n",
       "SEX                            int32\n",
       "EDUCATION                      int32\n",
       "MARRIAGE                       int32\n",
       "AGE                            int32\n",
       "PAY_1                          int32\n",
       "PAY_2                          int32\n",
       "PAY_3                          int32\n",
       "PAY_4                          int32\n",
       "PAY_5                          int32\n",
       "PAY_6                          int32\n",
       "BILL_AMT1                      int32\n",
       "BILL_AMT2                      int32\n",
       "BILL_AMT3                      int32\n",
       "BILL_AMT4                      int32\n",
       "BILL_AMT5                      int32\n",
       "BILL_AMT6                      int32\n",
       "PAY_AMT1                       int32\n",
       "PAY_AMT2                       int32\n",
       "PAY_AMT3                       int32\n",
       "PAY_AMT4                       int32\n",
       "PAY_AMT5                       int32\n",
       "PAY_AMT6                       int32\n",
       "default payment next month     int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to identify the data records which have zero values for all attributes (apart from ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero_mask = df == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_zero_mask = df_zero_mask.iloc[:,2:].all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(feature_zero_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's good. This is just 2 higher than the 313 duplicate IDs we have identified earlier. But even with non-duplicate IDs, having a data record with all 0s is not useful. So if we delete all 315 records with zero values, there is a chance that we may get rid of the records with duplicate IDs in a meaningful way. Let's do just that. First we create a new dataframe, called df_clean_1. This creates a copy of the original dataframe, but masked to NOT include (note the ~ symbol, which stands for negation) the records which contain the zero values) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to select the record IDs of the above records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1 = df.loc[~feature_zero_mask,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26664, 26)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26664"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_1['ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this appears to have worked. You can save the \"cleaner\" data set for further processing next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_1.to_csv('df_clean_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
